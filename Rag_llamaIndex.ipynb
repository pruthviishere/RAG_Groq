{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVMGZ0eHKN3W"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cndxquUE9b3E",
        "outputId": "de9ad4c8-e931-4291-cfa9-35af73136993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m241.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m251.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch)\n",
            "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m280.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m237.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m234.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m281.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m145.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m159.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.3.1 (from torch)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m142.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from torchvision)\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m215.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m243.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.12.1\n",
            "    Uninstalling sympy-1.12.1:\n",
            "      Successfully uninstalled sympy-1.12.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 10.4.0\n",
            "    Uninstalling pillow-10.4.0:\n",
            "      Successfully uninstalled pillow-10.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.15.4\n",
            "    Uninstalling filelock-3.15.4:\n",
            "      Successfully uninstalled filelock-3.15.4\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.2\n",
            "    Uninstalling torch-2.2.2:\n",
            "      Successfully uninstalled torch-2.2.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.1+cu121\n",
            "    Uninstalling torchvision-0.18.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "astropy 5.3.4 requires numpy<2,>=1.21, but you have numpy 2.0.0 which is incompatible.\n",
            "chromadb 0.5.3 requires numpy<2.0.0,>=1.22.5, but you have numpy 2.0.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.0 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "gradio 4.8.0 requires numpy~=1.0, but you have numpy 2.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.4.0 which is incompatible.\n",
            "langchain 0.2.6 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.0 which is incompatible.\n",
            "langchain-community 0.2.6 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.0 which is incompatible.\n",
            "llama-index-core 0.10.55 requires numpy<2.0.0, but you have numpy 2.0.0 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.0 which is incompatible.\n",
            "onnxruntime 1.18.1 requires numpy<2.0,>=1.21.6, but you have numpy 2.0.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.0.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.0 which is incompatible.\n",
            "transformers 4.42.4 requires numpy<2.0,>=1.17, but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pillow-10.4.0 sympy-1.13.1 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 typing-extensions-4.12.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0047b7ebc8084ae6b150dd4e8c7a1d36",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "mpmath",
                  "sympy",
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers --upgrade\n",
        "!pip install torch torchvision --upgrade --force-reinstall --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxg3ksF59a1Q",
        "outputId": "a3c706bc-fceb-4bb2-cb07-dc6d6198a284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOQDsP-Qiovd",
        "outputId": "5699839c-e6b3-41f5-e9d0-937a52d2d08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing accelerate==0.31.0...\n",
            "Installing aiofiles==23.2.1...\n",
            "Installing aiohttp==3.9.5...\n",
            "Installing aiosignal==1.3.1...\n",
            "Installing altair==5.3.0...\n",
            "Installing annotated-types==0.7.0...\n",
            "Installing anyio==4.4.0...\n",
            "Installing appnope @ file:///home/conda/feedstock_root/build_artifacts/appnope_1707233003401/work...\n",
            "Installing asgiref==3.8.1...\n",
            "Installing asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work...\n",
            "Installing attrs==23.2.0...\n",
            "Installing backoff==2.2.1...\n",
            "Installing bcrypt==4.1.3...\n",
            "Installing beautifulsoup4==4.12.3...\n",
            "Installing build==1.2.1...\n",
            "Installing cachetools==5.3.3...\n",
            "Installing certifi==2024.6.2...\n",
            "Installing charset-normalizer==3.3.2...\n",
            "Installing chroma-hnswlib==0.7.3...\n",
            "Installing chromadb==0.5.3...\n",
            "Installing click==8.1.7...\n",
            "Installing coloredlogs==15.0.1...\n",
            "Installing comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work...\n",
            "Installing contourpy==1.2.1...\n",
            "Installing ctransformers==0.2.27...\n",
            "Installing cycler==0.12.1...\n",
            "Installing dataclasses-json==0.6.7...\n",
            "Installing debugpy @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/debugpy_1699253073094/work...\n",
            "Installing decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work...\n",
            "Installing Deprecated==1.2.14...\n",
            "Installing dirtyjson==1.0.8...\n",
            "Installing distro==1.9.0...\n",
            "Installing dnspython==2.6.1...\n",
            "Installing email_validator==2.2.0...\n",
            "Installing eval_type_backport==0.2.0...\n",
            "Installing exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1720869315914/work...\n",
            "Installing executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work...\n",
            "Installing fastapi==0.111.0...\n",
            "Installing fastapi-cli==0.0.4...\n",
            "Installing ffmpy==0.3.2...\n",
            "Installing filelock==3.15.4...\n",
            "Installing flatbuffers==24.3.25...\n",
            "Installing fonttools==4.53.0...\n",
            "Installing frozenlist==1.4.1...\n",
            "Installing fsspec==2024.6.1...\n",
            "Installing google-auth==2.30.0...\n",
            "Installing googleapis-common-protos==1.63.2...\n",
            "Installing gradio==4.8.0...\n",
            "Installing gradio_client==0.7.1...\n",
            "Installing gradio_pdf==0.0.11...\n",
            "Installing greenlet==3.0.3...\n",
            "Installing grpcio==1.64.1...\n",
            "Installing h11==0.14.0...\n",
            "Installing httpcore==1.0.5...\n",
            "Installing httptools==0.6.1...\n",
            "Installing httpx==0.27.0...\n",
            "Installing huggingface-hub==0.24.0...\n",
            "Installing humanfriendly==10.0...\n",
            "Installing idna==3.7...\n",
            "Installing importlib_metadata==7.1.0...\n",
            "Installing importlib_resources==6.4.0...\n",
            "Installing ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1719845458456/work...\n",
            "Installing ipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1719582526268/work...\n",
            "Installing jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work...\n",
            "Installing Jinja2==3.1.4...\n",
            "Installing joblib==1.4.2...\n",
            "Installing jsonpatch==1.33...\n",
            "Installing jsonpointer==3.0.0...\n",
            "Installing jsonschema==4.22.0...\n",
            "Installing jsonschema-specifications==2023.12.1...\n",
            "Installing jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1716472197302/work...\n",
            "Installing jupyter_core @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyter_core_1701803168398/work...\n",
            "Installing kiwisolver==1.4.5...\n",
            "Installing kubernetes==30.1.0...\n",
            "Installing langchain==0.2.6...\n",
            "Installing langchain-community==0.2.6...\n",
            "Installing langchain-core==0.2.10...\n",
            "Installing langchain-openai==0.1.13...\n",
            "Installing langchain-text-splitters==0.2.2...\n",
            "Installing langchain-together==0.1.3...\n",
            "Installing langsmith==0.1.82...\n",
            "Installing llama-cloud==0.0.9...\n",
            "Installing llama-index==0.10.55...\n",
            "Installing llama-index-agent-openai==0.2.8...\n",
            "Installing llama-index-cli==0.1.12...\n",
            "Installing llama-index-core==0.10.55...\n",
            "Installing llama-index-embeddings-huggingface==0.2.2...\n",
            "Installing llama-index-embeddings-openai==0.1.10...\n",
            "Installing llama-index-indices-managed-llama-cloud==0.2.5...\n",
            "Installing llama-index-legacy==0.9.48...\n",
            "Installing llama-index-llms-groq==0.1.4...\n",
            "Installing llama-index-llms-openai==0.1.25...\n",
            "Installing llama-index-llms-openai-like==0.1.3...\n",
            "Installing llama-index-multi-modal-llms-openai==0.1.7...\n",
            "Installing llama-index-program-openai==0.1.6...\n",
            "Installing llama-index-question-gen-openai==0.1.3...\n",
            "Installing llama-index-readers-file==0.1.30...\n",
            "Installing llama-index-readers-json==0.1.5...\n",
            "Installing llama-index-readers-llama-parse==0.1.6...\n",
            "Installing llama-parse==0.4.8...\n",
            "Installing markdown-it-py==3.0.0...\n",
            "Installing MarkupSafe==2.1.5...\n",
            "Installing marshmallow==3.21.3...\n",
            "Installing matplotlib==3.9.0...\n",
            "Installing matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work...\n",
            "Installing mdurl==0.1.2...\n",
            "Installing minijinja==2.0.1...\n",
            "Installing mmh3==4.1.0...\n",
            "Installing monotonic==1.6...\n",
            "Installing mpmath==1.3.0...\n",
            "Installing multidict==6.0.5...\n",
            "Installing mypy-extensions==1.0.0...\n",
            "Installing nest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work...\n",
            "Installing networkx==3.3...\n",
            "Installing nltk==3.8.1...\n",
            "Installing numpy==1.26.4...\n",
            "Installing oauthlib==3.2.2...\n",
            "Installing onnxruntime==1.18.1...\n",
            "Installing openai==1.35.7...\n",
            "Installing opentelemetry-api==1.25.0...\n",
            "Installing opentelemetry-exporter-otlp-proto-common==1.25.0...\n",
            "Installing opentelemetry-exporter-otlp-proto-grpc==1.25.0...\n",
            "Installing opentelemetry-instrumentation==0.46b0...\n",
            "Installing opentelemetry-instrumentation-asgi==0.46b0...\n",
            "Installing opentelemetry-instrumentation-fastapi==0.46b0...\n",
            "Installing opentelemetry-proto==1.25.0...\n",
            "Installing opentelemetry-sdk==1.25.0...\n",
            "Installing opentelemetry-semantic-conventions==0.46b0...\n",
            "Installing opentelemetry-util-http==0.46b0...\n",
            "Installing orjson==3.10.5...\n",
            "Installing overrides==7.7.0...\n",
            "Installing packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1718189413536/work...\n",
            "Installing pandas==2.2.2...\n",
            "Installing parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work...\n",
            "Installing pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1706113125309/work...\n",
            "Installing pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work...\n",
            "Installing pillow==10.4.0...\n",
            "Installing platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1715777629804/work...\n",
            "Installing posthog==3.5.0...\n",
            "Installing prompt_toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1718047967974/work...\n",
            "Installing protobuf==4.25.3...\n",
            "Installing psutil @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/psutil_1699248249804/work...\n",
            "Installing ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl...\n",
            "Installing pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work...\n",
            "Installing py-cpuinfo==9.0.0...\n",
            "Installing pyarrow==16.1.0...\n",
            "Installing pyasn1==0.6.0...\n",
            "Installing pyasn1_modules==0.4.0...\n",
            "Installing pydantic==2.8.0...\n",
            "Installing pydantic_core==2.20.0...\n",
            "Installing pydub==0.25.1...\n",
            "Installing Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1714846767233/work...\n",
            "Installing pyparsing==3.1.2...\n",
            "Installing pypdf==4.2.0...\n",
            "Installing PyPDF2==3.0.1...\n",
            "Installing PyPika==0.48.9...\n",
            "Installing pyproject_hooks==1.1.0...\n",
            "Installing python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work...\n",
            "Installing python-dotenv==1.0.1...\n",
            "Installing python-multipart==0.0.9...\n",
            "Installing pytz==2024.1...\n",
            "Installing PyYAML==6.0.1...\n",
            "Installing pyzmq @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_43pxpbos3z/croot/pyzmq_1705605108344/work...\n",
            "Installing referencing==0.35.1...\n",
            "Installing regex==2024.5.15...\n",
            "Installing requests==2.32.3...\n",
            "Installing requests-oauthlib==2.0.0...\n",
            "Installing rich==13.7.1...\n",
            "Installing rpds-py==0.18.1...\n",
            "Installing rsa==4.9...\n",
            "Installing safetensors==0.4.3...\n",
            "Installing scikit-learn==1.5.0...\n",
            "Installing scipy==1.14.0...\n",
            "Installing semantic-version==2.10.0...\n",
            "Installing sentence-transformers==3.0.1...\n",
            "Installing sentencepiece==0.2.0...\n",
            "Installing setuptools==69.5.1...\n",
            "Installing shellingham==1.5.4...\n",
            "Installing six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work...\n",
            "Installing sniffio==1.3.1...\n",
            "Installing soupsieve==2.5...\n",
            "Installing SQLAlchemy==2.0.31...\n",
            "Installing stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work...\n",
            "Installing starlette==0.37.2...\n",
            "Installing striprtf==0.0.26...\n",
            "Installing sympy==1.12.1...\n",
            "Installing tabulate==0.9.0...\n",
            "Installing tenacity==8.4.2...\n",
            "Installing threadpoolctl==3.5.0...\n",
            "Installing tiktoken==0.7.0...\n",
            "Installing together==1.2.1...\n",
            "Installing tokenizers==0.19.1...\n",
            "Installing tomlkit==0.12.0...\n",
            "Installing toolz==0.12.1...\n",
            "Installing torch==2.2.2...\n",
            "Installing tornado @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tornado_1699243541634/work...\n",
            "Installing tqdm==4.66.4...\n",
            "Installing traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1713535121073/work...\n",
            "Installing transformers==4.42.4...\n",
            "Installing typer==0.12.3...\n",
            "Installing typing-inspect==0.9.0...\n",
            "Installing typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1717802530399/work...\n",
            "Installing tzdata==2024.1...\n",
            "Installing ujson==5.10.0...\n",
            "Installing urllib3==2.2.2...\n",
            "Installing uvicorn==0.30.1...\n",
            "Installing uvloop==0.19.0...\n",
            "Installing watchfiles==0.22.0...\n",
            "Installing wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work...\n",
            "Installing websocket-client==1.8.0...\n",
            "Installing websockets==11.0.3...\n",
            "Installing wheel==0.43.0...\n",
            "Installing wrapt==1.16.0...\n",
            "Installing yarl==1.9.4...\n",
            "Installing zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1718013267051/work...\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "with open('requirements.txt', 'r') as f:\n",
        "    requirements = [line.strip() for line in f.readlines()]\n",
        "\n",
        "for requirement in requirements:\n",
        "    print(f\"Installing {requirement}...\")\n",
        "    subprocess.run(['pip', 'install', '-q', requirement])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "y4-g6KpVaatj",
        "outputId": "5211361b-0181-4fa0-ebd2-b4d57650fed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.0\n",
            "    Uninstalling numpy-2.0.0:\n",
            "      Successfully uninstalled numpy-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3df108a5a17f416f810853a6bbea6eb7",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade numpy==1.24.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4twTqGyVKR9h"
      },
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8CJfvrih0hr"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lvuvkjyr2Jj-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "class Config:\n",
        "    _instance = None\n",
        "\n",
        "    def __new__(cls):\n",
        "        if cls._instance is None:\n",
        "            cls._instance = super(Config, cls).__new__(cls)\n",
        "            cls._instance.config_file_path = os.path.join(os.getcwd(), \"config.conf\")\n",
        "        return cls._instance\n",
        "\n",
        "    def read_config(self):\n",
        "        try:\n",
        "            with open(self.config_file_path, \"r\") as config_file:\n",
        "                conf = json.load(config_file)\n",
        "                return conf\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File '{self.config_file_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkqDRtQ-h0hr",
        "outputId": "334965fc-c98d-429e-d86a-a15e69ab44fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.indices import VectorStoreIndex\n",
        "\n",
        "from llama_index.core import Document\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import StorageContext\n",
        "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "# from IPython.display import Markdown, display\n",
        "from typing import Any\n",
        "from llama_index.core import SimpleDirectoryReader, SummaryIndex\n",
        "from llama_index.core.callbacks import CallbackManager\n",
        "from llama_index.core.llms import (\n",
        "    CustomLLM,\n",
        "    CompletionResponse,\n",
        "    CompletionResponseGen,\n",
        "    LLMMetadata,\n",
        ")\n",
        "from llama_index.core.llms.callbacks import llm_completion_callback\n",
        "# from openai import OpenAI\n",
        "\n",
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
        "from llama_index.core.storage.index_store import SimpleIndexStore\n",
        "from llama_index.core.vector_stores import SimpleVectorStore\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "\n",
        "from os import path\n",
        "from glob import glob\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.readers.file import (\n",
        "    DocxReader,\n",
        "    HWPReader,\n",
        "    PDFReader,\n",
        "    EpubReader,\n",
        "    FlatReader,\n",
        "    HTMLTagReader,\n",
        "    ImageCaptionReader,\n",
        "    ImageReader,\n",
        "    ImageVisionLLMReader,\n",
        "    IPYNBReader,\n",
        "    MarkdownReader,\n",
        "    MboxReader,\n",
        "    PptxReader,\n",
        "    PandasCSVReader,\n",
        "    VideoAudioReader,\n",
        "    UnstructuredReader,\n",
        "    PyMuPDFReader,\n",
        "    ImageTabularChartReader,\n",
        "    XMLReader,\n",
        "    PagedCSVReader,\n",
        "    CSVReader,\n",
        "    RTFReader,\n",
        "\n",
        ")\n",
        "\n",
        "from llama_index.readers.json import JSONReader\n",
        "from llama_index.core.node_parser import SimpleFileNodeParser\n",
        "from llama_index.readers.file import FlatReader\n",
        "from pathlib import Path\n",
        "\n",
        "import logging\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "class Ingest:\n",
        "\n",
        "    _embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "    def __init__(self):\n",
        "        self.config = Config().read_config()\n",
        "        self.index = None\n",
        "        self.storage = None\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.logger.setLevel(logging.DEBUG)\n",
        "\n",
        "        # Create a file handler and set the level to DEBUG\n",
        "        file_handler = logging.FileHandler('ingest.log')\n",
        "        file_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "        # Create a formatter and set the format for the log messages\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add the file handler to the logger\n",
        "        self.logger.addHandler(file_handler)\n",
        "\n",
        "    def load_index(self):\n",
        "        try:\n",
        "            self.load_storage()\n",
        "            if self.index is None:\n",
        "                self.index = load_index_from_storage(self.storage, embed_model=Ingest._embed_model, show_progress=True)\n",
        "                # self.index.set_index_id(self.config['index_id'])\n",
        "                self.logger.info(f\"loaded index: {str(self.config['index_id'])}\")\n",
        "                print(\"\\n load index times \")\n",
        "            return self.index\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading index: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_storage(self):\n",
        "        try:\n",
        "            if self.storage is None:\n",
        "                self.storage = StorageContext.from_defaults(persist_dir=self.config['persist_dir'])\n",
        "                self.logger.info(f\"loaded storage: {str(self.config['persist_dir'])}\")\n",
        "            return self.storage\n",
        "        except FileNotFoundError as fnfe:\n",
        "            \"\"\"docstore.json No such file\n",
        "            means we don't have store at dir\n",
        "            we will create one\n",
        "            \"\"\"\n",
        "            print(\" is it catching ? yes \")\n",
        "            self.logger.info(f\"Error loading storage: {str(fnfe)}\")\n",
        "            storage_context = StorageContext.from_defaults(\n",
        "            docstore=SimpleDocumentStore(),\n",
        "            vector_store=SimpleVectorStore(),\n",
        "            index_store=SimpleIndexStore(),\n",
        "            )\n",
        "            persist_dir = self.config['persist_dir']\n",
        "            # index_id =self.config['index_id']\n",
        "            node = TextNode(id_=\"first\", text=\"You are basic RAG on QA developed by Pruthviraj J\")\n",
        "            nodes = [node]\n",
        "\n",
        "            index = VectorStoreIndex(nodes, embed_model=Ingest._embed_model )\n",
        "            # index.add_node(node)\n",
        "            # index.set_index_id(index_id)\n",
        "            # storage_context.persist(persist_dir=persist_dir)\n",
        "            self.index = index\n",
        "            self.storage = storage_context\n",
        "            self.index.storage_context.persist(persist_dir=persist_dir)\n",
        "            self.storage.persist(persist_dir=persist_dir)\n",
        "            self.storage = StorageContext.from_defaults(persist_dir=self.config['persist_dir'])\n",
        "\n",
        "            return self.storage\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading storage: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def put(self):\n",
        "        try:\n",
        "            self.load_storage()\n",
        "            self.load_index()\n",
        "\n",
        "\n",
        "            parser = SentenceSplitter(chunk_size=self.config['chunk_size'], chunk_overlap=self.config['chunk_overlap'])\n",
        "            documents = self.get_pdf()\n",
        "            nodes = parser.get_nodes_from_documents(documents, show_progress=True)\n",
        "            # self.storage.docstore.add_documents(nodes)\n",
        "\n",
        "            # index = VectorStoreIndex(nodes, embed_model=Ingest._embed_model)\n",
        "            # self.index.set_index_id(self.config['index_id'])\n",
        "            self.index.insert_nodes(nodes)\n",
        "            self.index.storage_context.persist(persist_dir=self.config['persist_dir'])\n",
        "            print(\"put done\")\n",
        "            self.logger.info(\"Put operation completed successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error putting data: {str(e)}\")\n",
        "            raise\n",
        "    def put(self,documents):\n",
        "        try:\n",
        "            self.load_storage()\n",
        "            self.load_index()\n",
        "            parser = SentenceSplitter(chunk_size=self.config['chunk_size'], chunk_overlap=self.config['chunk_overlap'])\n",
        "            # documents = self.get_pdf()\n",
        "\n",
        "            nodes = parser.get_nodes_from_documents(documents, show_progress=True)\n",
        "            self.index.insert_nodes(nodes)\n",
        "            self.index.storage_context.persist(persist_dir=self.config['persist_dir'])\n",
        "            print(\"put done documents\")\n",
        "            self.logger.info(\"Put operation completed successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error putting data: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "    def ingest_gen_doc(self,file_path=None, directory=None):\n",
        "\n",
        "        if file_path is not None :\n",
        "            # print(\"file\")\n",
        "            print(\"filepath \"+file_path)\n",
        "            reader = DocumentReader(file_path)\n",
        "            docs = reader.load_data_generic()\n",
        "            self.put(docs)\n",
        "        elif directory:\n",
        "            # print(\"dir \")\n",
        "            print(\"directory  \"+directory)\n",
        "            reader = DocumentReader(directory= directory,file_path=None)\n",
        "            docs = reader.load_data_generic()\n",
        "            if(docs is None or len(docs)==0):\n",
        "                print(\"no docs in dir \")\n",
        "                return False\n",
        "            else :\n",
        "                self.put(docs)\n",
        "                print(\"ingest_gen_doc success \")\n",
        "                return True\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_jAbPkPh0hs"
      },
      "source": [
        "from ingest import Ingest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TjxFt4YkIF5x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UYKAQ0s6h0ht"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DocumentReader:\n",
        "    def __init__(self, file_path=None, directory=None):\n",
        "        self.file_path = file_path\n",
        "        self.directory = directory\n",
        "\n",
        "    def get_reader(self, file_path):\n",
        "        # Implement the logic to determine the reader based on the file extension\n",
        "        # For example:\n",
        "        file_ext = os.path.splitext(file_path)[1][1:].lower()\n",
        "        readers = {\n",
        "            \"docx\": DocxReader,\n",
        "            \"hwp\": HWPReader,\n",
        "            \"pdf\": PDFReader,\n",
        "            \"docx\": DocxReader,\n",
        "            \"hwp\": HWPReader,\n",
        "            \"pdf\": PDFReader,\n",
        "            \"epub\": EpubReader,\n",
        "            \"txt\": FlatReader,\n",
        "            \"html\": HTMLTagReader,\n",
        "            \"jpg\": ImageCaptionReader,\n",
        "            \"jpeg\": ImageCaptionReader,\n",
        "            \"png\": ImageCaptionReader,\n",
        "            \"ipynb\": IPYNBReader,\n",
        "            \"md\": MarkdownReader,\n",
        "            \"mbox\": MboxReader,\n",
        "            \"pptx\": PptxReader,\n",
        "            \"csv\": PandasCSVReader,\n",
        "            \"mp3\": VideoAudioReader,\n",
        "            \"mp4\": VideoAudioReader,\n",
        "            \"wav\": VideoAudioReader,\n",
        "            \"xml\": XMLReader,\n",
        "            \"pagedcsv\": PagedCSVReader,\n",
        "            \"rtf\": RTFReader,\n",
        "        }\n",
        "        if file_ext == \"json\":\n",
        "            return JSONReader(levels_back=0)\n",
        "        # if not found return un\n",
        "        return readers.get(file_ext, UnstructuredReader)\n",
        "\n",
        "    def load_data_generic(self):\n",
        "        if self.file_path and not os.path.isdir(self.file_path):\n",
        "            file_ext = os.path.splitext(self.file_path)[1][1:].lower()\n",
        "            if file_ext == \"json\":\n",
        "                reader = JSONReader(levels_back=0)\n",
        "            else:\n",
        "                reader = self.get_reader(self.file_path)()# this is required to create instance\n",
        "            print(\"reader \",reader)\n",
        "            return reader.load_data(file = self.file_path)\n",
        "        elif self.directory:\n",
        "            documents = []\n",
        "            print(\"elif dir \"+self.directory)\n",
        "            for file in os.listdir(self.directory):\n",
        "                file_path = os.path.join(self.directory, file)\n",
        "                # print(\"fp \", file_path)\n",
        "                if os.path.isfile(file_path):\n",
        "                    file_ext = os.path.splitext( file_path)[1][1:].lower()\n",
        "                    print(\" filetype \",file_ext)\n",
        "                    if file_ext == \"json\":\n",
        "                        reader = JSONReader(levels_back=0)\n",
        "                        docs = reader.load_data(input_file = file_path)\n",
        "                    else:\n",
        "                        reader = self.get_reader(file_path)()# this is required to create instance\n",
        "                        docs = reader.load_data(file = file_path)\n",
        "                    documents.extend(docs)\n",
        "                    print(\"doc size \", len(documents))\n",
        "            return documents\n",
        "        else:\n",
        "            print(\"in else\")\n",
        "            return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "4hUNz61Dh0ht",
        "outputId": "495de5d6-4570-4bf6-96a2-6115c7863586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:loaded storage: /content/persist\n",
            "INFO:__main__:loaded index: 26jun\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first index \n",
            "IMPORTANT: You are using gradio version 4.8.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "\n",
            " load index times \n",
            "first llm\n",
            "first embdee\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://de434b1c9141605c22.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://de434b1c9141605c22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from llama_index.core.settings import Settings\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "import gradio as gr\n",
        "import os\n",
        "from gradio_pdf import PDF\n",
        "\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "class Rag:\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed_model = None\n",
        "        self.llm_model = None\n",
        "        self.index = None\n",
        "\n",
        "    def get_llm_model(self):\n",
        "        if self.llm_model :\n",
        "            return self.llm_model\n",
        "        else:\n",
        "            print(\"first llm\")\n",
        "            from google.colab import userdata\n",
        "            llm = Groq(model=\"llama3-70b-8192\",api_key=userdata.get('GROQ_API_KEY'))\n",
        "            self.llm_model =  llm\n",
        "    def get_embed_model(self):\n",
        "        if self.embed_model :\n",
        "            return self.embed_model\n",
        "        else:\n",
        "            print(\"first embdee\")\n",
        "            embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "            self.embed_model =  embed_model\n",
        "\n",
        "    def get_index(self):\n",
        "        if self.index :\n",
        "            return self.index\n",
        "        else:\n",
        "            print(\"first index \")\n",
        "            self.index = Ingest().load_index()\n",
        "\n",
        "rag = Rag()\n",
        "def ask_question(question):\n",
        "    # Query the index with the question\n",
        "    index =  rag.get_index()\n",
        "    llm_model =  rag.get_llm_model()\n",
        "    embed_model =   rag.get_embed_model()\n",
        "    query_engine = index.as_query_engine(llm=llm_model)\n",
        "    response = query_engine.query(question)\n",
        "    return response\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            question_text = gr.Textbox(label=\"Ask a Question\")\n",
        "            btn_ask = gr.Button(\"Ask\")\n",
        "            output_ask = gr.Textbox(label=\"Answer\")\n",
        "            btn_ask.click(ask_question, inputs=question_text, outputs=output_ask)\n",
        "if __name__ == \"__main__\":\n",
        "    # rag = Rag()\n",
        "    os.environ['GRADIO_ANALYTICS_ENABLED'] = 'False'\n",
        "    index = rag.get_index()\n",
        "    llm_model = rag.get_llm_model()\n",
        "    embed_model =  rag.get_embed_model()\n",
        "# server_name=\"0.0.0.0\", server_port=5000, auth=(\"user\", \"DocAI\")\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "coW4N6GObfmn"
      },
      "outputs": [],
      "source": [
        "ingestobj = Ingest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "28a680711e924918b87bf4afc2633560",
            "9bd557672dd04c4a8826266f03a9b648",
            "d3a9f3eee5cf44f38f0c71207ac1034b",
            "c2938df0a9e44ae189f54bdcdc23ba8f",
            "0c3e0ec190dd4d10a065e4fa5e5f6ae6",
            "c4d8b63a4119444194ca9b47751eb71a",
            "f85e4c38230e475e9ed61ca3381746a3",
            "4ee23a8e335b41e398155dd8e0e402fc",
            "be48608c13bb416a928a406a51ebd732",
            "fb5197498c504bdca550d5fa7bb2c514",
            "be632013720740e4bdc5d0d0f92a2df5"
          ]
        },
        "id": "aP_1H3NDh0ht",
        "outputId": "ab0d8040-49b9-4c8d-b8ab-b7dbbcef1b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filepath /content/DECART.pdf\n",
            "reader  <llama_index.readers.file.docs.base.PDFReader object at 0x7ae69c0ed810>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Error loading storage: [Errno 2] No such file or directory: '/content/persist/docstore.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " is it catching ? yes \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28a680711e924918b87bf4afc2633560",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Put operation completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "put done documents\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = r\"/content/DECART.pdf\"\n",
        "ingestobj.ingest_gen_doc(file_path= file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iVMGZ0eHKN3W"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fgpt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c3e0ec190dd4d10a065e4fa5e5f6ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a680711e924918b87bf4afc2633560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bd557672dd04c4a8826266f03a9b648",
              "IPY_MODEL_d3a9f3eee5cf44f38f0c71207ac1034b",
              "IPY_MODEL_c2938df0a9e44ae189f54bdcdc23ba8f"
            ],
            "layout": "IPY_MODEL_0c3e0ec190dd4d10a065e4fa5e5f6ae6"
          }
        },
        "4ee23a8e335b41e398155dd8e0e402fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd557672dd04c4a8826266f03a9b648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d8b63a4119444194ca9b47751eb71a",
            "placeholder": "​",
            "style": "IPY_MODEL_f85e4c38230e475e9ed61ca3381746a3",
            "value": "Parsing nodes: 100%"
          }
        },
        "be48608c13bb416a928a406a51ebd732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be632013720740e4bdc5d0d0f92a2df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2938df0a9e44ae189f54bdcdc23ba8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5197498c504bdca550d5fa7bb2c514",
            "placeholder": "​",
            "style": "IPY_MODEL_be632013720740e4bdc5d0d0f92a2df5",
            "value": " 8/8 [00:00&lt;00:00, 93.74it/s]"
          }
        },
        "c4d8b63a4119444194ca9b47751eb71a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a9f3eee5cf44f38f0c71207ac1034b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee23a8e335b41e398155dd8e0e402fc",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be48608c13bb416a928a406a51ebd732",
            "value": 8
          }
        },
        "f85e4c38230e475e9ed61ca3381746a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb5197498c504bdca550d5fa7bb2c514": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
